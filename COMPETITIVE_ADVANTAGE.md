# Crowdwave Competitive Advantage: Evidence Base

## The Problem with Raw LLM Predictions

### ForecastBench Data (Oct 2025)
**Source:** Forecasting Research Institute (peer-reviewed benchmark)

| Forecaster | Brier Score | Notes |
|------------|-------------|-------|
| Superforecasters | **0.081** | Best human performers |
| GPT-4.5 | 0.101 | Best raw LLM |
| GPT-4 | 0.131 | Previous generation |
| Median public | 0.150+ | Non-expert humans |

**Key insight:** Best LLMs are still **25% worse** than superforecasters.

### Synthetic Survey Accuracy (Dig Insights, 2025)
**Source:** Independent validation study (500 synthetic respondents, 30 movies)

| Task | Correlation | Quality |
|------|-------------|---------|
| Backcasting (known events) | 0.85 | Good |
| Forecasting (future events) | 0.50 | Weak |
| New products (never seen) | **0.30** | Barely above chance |

**Key insight:** Synthetic data **fails at exactly what clients need most** — predicting success of new/untested concepts.

---

## Why Calibration Is the Answer

### The Crowdwave Approach

We don't use raw LLM predictions. We:

1. **Collect human survey benchmarks** from authoritative sources (Pew, Gallup, McKinsey, etc.)
2. **Measure systematic LLM biases** by comparing predictions to actuals
3. **Derive correction multipliers** that adjust for known error patterns
4. **Apply domain-specific calibrations** based on validated human data
5. **Track accuracy continuously** against new outcomes

### What This Solves

| Raw LLM Problem | Crowdwave Solution |
|-----------------|-------------------|
| Over-predicts AI concern | ×0.90 multiplier (validated) |
| Under-predicts senior tech adoption | ×1.30-1.65 multiplier |
| Misses status quo bias | +15-20 pts for incumbents |
| Wrong on polarized topics | Segment by party (required) |
| Inflates intent-to-action | ×0.55-0.85 by category |
| Misses industry NPS variance | +25 pts manufacturing, -10 pts software B2B |

---

## Evidence of Calibration Improvement

### Domain Coverage

| Domain | Sources | Sample Size | Status |
|--------|---------|-------------|--------|
| NPS by Industry | Survicate, Retently | 5.4M+ responses | ✅ |
| Political/Social | Gallup | 13,000+ | ✅ |
| Executive Concerns | Conference Board | 1,732 | ✅ |
| Consumer Behavior | McKinsey, Deloitte | Industry-wide | ✅ |
| Technology Adoption | AARP, Pew | 10,000+ | ✅ |
| Cruise/Travel | CLIA, JD Power | Industry-wide | ✅ |
| Institutional Trust | Edelman | 33,000 | ✅ |
| Healthcare | KFF, Gallup | 5,000+ | ✅ |
| Workplace | Gallup | 10,000+ | ✅ |
| Financial | Federal Reserve SHED | National | ✅ |

**Total validated data points:** 100+ benchmarks across 20+ domains

### Documented LLM Biases (8 Patterns)

1. **Position bias** — Middle-context info gets lost (MIT/Stanford)
2. **Source framing bias** — Influenced by how info is presented
3. **Acquiescence bias** — Tends toward agreement
4. **Sycophancy/anchoring** — Follows user cues
5. **Overconfidence** — Too certain on edge cases
6. **Temporal bias** — Training data cutoff effects
7. **Generalization bias** — Over-applies patterns
8. **Demographic bias** — Over-represents majority groups

**Each has documented correction factors.**

---

## Competitive Comparison

### vs. Raw LLM Predictions

| Metric | Raw LLM | Crowdwave Calibrated |
|--------|---------|---------------------|
| Uses human validation | ❌ | ✅ |
| Corrects known biases | ❌ | ✅ |
| Domain-specific adjustments | ❌ | ✅ |
| Tracks accuracy over time | ❌ | ✅ |
| Sample size backing | 0 | 5M+ |

### vs. Synthetic Survey Competitors

| Capability | Typical Competitor | Crowdwave |
|------------|-------------------|-----------|
| Forecasting accuracy (new concepts) | 0.30 correlation | Calibrated to human data |
| Validation methodology | Unvalidated | Brier score + MAE tracking |
| Bias correction | None | 8 documented patterns |
| Domain coverage | Generic | 20+ domains validated |
| Transparency | Black box | Full methodology documented |

### vs. Traditional Research

| Factor | Traditional Survey | Crowdwave |
|--------|-------------------|-----------|
| Speed | Weeks | Minutes |
| Cost | $50K-$500K | Fraction |
| Sample size | 500-2,000 | Unlimited |
| Accuracy (established topics) | Gold standard | Calibrated to match |
| Accuracy (new concepts) | Gold standard | Use with validation |

---

## When to Use Crowdwave (Honest Assessment)

### ✅ High Confidence Use Cases

- **Established topics** with human benchmark data
- **Directional guidance** before full research
- **Concept screening** at scale
- **Trend analysis** in validated domains
- **Audience sizing** for known segments
- **Competitive analysis** against benchmarks

### ⚠️ Use with Validation

- **New product concepts** (recommend human sample for validation)
- **Emerging categories** (less calibration data available)
- **High-stakes decisions** (layer with real consumer input)

### ❌ Not Recommended Alone

- **Truly novel innovations** with no comparable data
- **Regulatory/legal decisions** requiring human evidence
- **Cultural nuances** in under-researched markets

---

## Client-Ready Proof Points

### Accuracy Claims We Can Make

1. **"Calibrated against 5M+ human survey responses"** — True
2. **"20+ domains with validated benchmarks"** — True
3. **"Documented correction factors for 8 LLM bias patterns"** — True
4. **"Tracks Brier score for continuous accuracy monitoring"** — True

### Claims We Avoid

- ❌ "95% accuracy" (unvalidated industry claim)
- ❌ "Replaces traditional research" (overpromise)
- ❌ "Works for any question" (not true for novel concepts)

---

## Accuracy Improvement Trajectory

### ForecastBench LLM Progress
- GPT-4 (Mar 2023): Brier 0.131
- GPT-4.5 (Feb 2025): Brier 0.101
- Rate: ~0.016 Brier pts/year improvement
- Projected parity with superforecasters: Late 2026

### Crowdwave Edge
Even as raw LLMs improve, calibration provides:
- **Faster accuracy** — Don't wait for model improvements
- **Domain expertise** — Validated in specific verticals
- **Transparency** — Know when predictions are reliable
- **Continuous learning** — Update calibrations as new data arrives

---

## Summary: Why Crowdwave Wins

| Factor | Evidence |
|--------|----------|
| **Data Foundation** | 100+ benchmarks, 5M+ responses |
| **Methodology** | Brier score tracking, documented biases |
| **Transparency** | Full calibration methodology available |
| **Honest Claims** | No "95% accuracy" hype |
| **Continuous Improvement** | New calibrations added regularly |
| **Domain Depth** | 20+ validated domains |

**Bottom line:** We're not claiming magic. We're showing our work. That's what separates best-in-class from marketing hype.
